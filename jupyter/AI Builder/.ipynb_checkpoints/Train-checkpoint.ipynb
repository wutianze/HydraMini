{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train AI model Notebook\n",
    "\n",
    "This notebook illustrates how to train a model in your PC.\n",
    "\n",
    "## Preparation in PC\n",
    "The host pc should be ubuntu 16.04, you can refer to [this](https://github.com/wutianze/dnndk3.0-pynqz2) to build an environment for DNNDK_v3.0 using tensorflow.\n",
    "\n",
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Cropping2D,BatchNormalization\n",
    "from keras.models import load_model, Model, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import plot_model\n",
    "import argparse\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './model' # where to save the model trained\n",
    "READ_PATH = './images' # where to read the images\n",
    "OUTPUT_NUM = 2 # here we output throttle value and steer value, so is 2\n",
    "CUT_SIZE = 40 # we cut the top n pixels of the input images, so the final input size is 160*80\n",
    "EPOCH_NUM = 20 # train n epochs\n",
    "IMAGE_SHAPE = [120,160,3]# will be set autonomously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the image names and related labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start loading data list from:\"+READ_PATH)\n",
    "with open(READ_PATH+\"/train.csv\") as f:\n",
    "    files = list(csv.reader(f))\n",
    "    single_image = cv2.imread(READ_PATH+'/'+files[0][0])\n",
    "    IMAGE_SHAPE[0] = single_image.shape[0]-CUT_SIZE\n",
    "    IMAGE_SHAPE[1] = single_image.shape[1]\n",
    "    IMAGE_SHAPE[2] = single_image.shape[2]\n",
    "print(\"IMAGE_SHAPE:\")\n",
    "print(IMAGE_SHAPE)\n",
    "print(\"ORIGINAL_LABEL_NUM:%d\"%(len(files[0])-1))\n",
    "cut = int(len(files)*0.8)\n",
    "train_list = files[0:cut]\n",
    "valid_list = files[cut:]\n",
    "total_number_img = len(train_list) + len(valid_list)\n",
    "print(\"total images number is:%d\"%(total_number_img))\n",
    "print(\"Load Data list Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('parameters')\n",
    "print('-'*30)\n",
    "\n",
    "keep_prob = 0.1\n",
    "# learning_rate must be smaller than 0.0001\n",
    "learning_rate = 0.0001\n",
    "batch_size = 30\n",
    "samples_per_epoch = total_number_img / batch_size\n",
    "\n",
    "print('keep_prob = ', keep_prob)\n",
    "print('learning_rate = ', learning_rate)\n",
    "print('nb_epoch = ', EPOCH_NUM)\n",
    "print('samples_per_epoch = ', samples_per_epoch)\n",
    "print('batch_size = ', batch_size)\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the AI model\n",
    "The following picture shows the network structure now.\n",
    "![network](./imgs/ns.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start compile\")\n",
    "model = Sequential()\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\",input_shape=(IMAGE_SHAPE[0],IMAGE_SHAPE[1],IMAGE_SHAPE[2])))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Conv2D(32, (5, 5), strides=(2, 2), activation=\"relu\"))\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Conv2D(64, (5, 5), strides=(2, 2), activation=\"relu\"))\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1,1), activation=\"relu\"))    \n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dropout(keep_prob))\n",
    "model.add(Dense(OUTPUT_NUM,activation=\"relu\"))\n",
    "#model.add(Dense(OUTPUT_NUM,activation='softmax'))\n",
    "model.summary()\n",
    "print(\"build finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data generator function\n",
    "This function is used to generate training data in keras. In this function we also preprocess the initial images.\n",
    "### Why we need preprocess?\n",
    "1. The initial images may not meet the requirements of the model input, for example, the image size is 1020\\*720 while the input size is 160\\*120.\n",
    "2. The model's performance highly depends on the input quality and there exists many ways to make the images more suitable for training such as normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(name_list, batch_size):\n",
    "    while True:\n",
    "        images = np.zeros([batch_size, IMAGE_SHAPE[0], IMAGE_SHAPE[1], IMAGE_SHAPE[2]])\n",
    "        labels = np.zeros([batch_size, OUTPUT_NUM])\n",
    "        #for index in np.random.permutation(X.shape[0]):\n",
    "        i = 0\n",
    "        for index in np.random.permutation(len(name_list)):\n",
    "            # this line defines how images are processed, should be same as that in graph_input_fn\n",
    "            images[i] = cv2.imread(READ_PATH+'/'+name_list[index][0])[CUT_SIZE:,:]/255.0-0.5\n",
    "            # Now the labels in `train.csv` are the car's steer and throttle values. They both range from -1.0-1.0, before we put them into the model, we change them to 0.0-1.0 by `(value + 1)/2`.\n",
    "            if OUTPUT_NUM == 1:\n",
    "                labels[i] = [(float(name_list[index][1])+1.)/2.]\n",
    "            elif OUTPUT_NUM ==2:\n",
    "                labels[i] = [(float(name_list[index][1])+1.)/2.,(float(name_list[index][2])+1.)/2.]\n",
    "            #print(labels[i])\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                i = 0\n",
    "                yield (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, learning_rate, nb_epoch, samples_per_epoch,\n",
    "                batch_size, train_list, valid_list, model_path):\n",
    "    if not os.path.exists(model_path+'/'):\n",
    "        os.mkdir(model_path+'/')\n",
    "\n",
    "    #checkpoint = ModelCheckpoint(model_path+'/model-{epoch:03d}.h5',\n",
    "    checkpoint = ModelCheckpoint(model_path+'/model.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=0,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=.0005, patience=20,\n",
    "                               verbose=1, mode='min')\n",
    "    tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=20, write_graph=True,write_grads=True,\n",
    "                              write_images=True, embeddings_freq=0, embeddings_layer_names=None,\n",
    "                              embeddings_metadata=None)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=0, mode='min', min_delta=1e-5,cooldown=3, min_lr=0)\n",
    "\n",
    "    \n",
    "    #model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate),loss='mean_squared_error') # for congression model\n",
    "    \n",
    "    model.fit_generator(batch_generator(train_list, batch_size),\n",
    "                        steps_per_epoch=samples_per_epoch/batch_size,\n",
    "                        epochs = nb_epoch,\n",
    "                        max_queue_size=1,\n",
    "                        validation_data=batch_generator(valid_list, batch_size),\n",
    "                        validation_steps=len(valid_list)/batch_size,\n",
    "                        callbacks=[tensorboard, checkpoint, early_stop, reduce_lr],\n",
    "                        verbose=2)\n",
    "# here we run the function, please pay attention to the parameters\n",
    "train_model(model, learning_rate, EPOCH_NUM, samples_per_epoch, batch_size, train_list, valid_list,MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now check your **MODEL_PATH**, have you seen the generated model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
